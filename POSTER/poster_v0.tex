\documentclass[sanserif,mathserif,final,16pt]{beamer}
\mode<presentation>{\usetheme{SPIRE}}

\usepackage{amsmath,amsfonts,amssymb,pxfonts,xspace}
\usepackage{graphicx,multirow}
\usepackage[size=custom,width=120,height=90,scale=1.2]{beamerposter}
\usepackage[listings,theorems]{tcolorbox}
\usepackage{setspace}
\usepackage{color,xcolor}
\usepackage{booktabs,subcaption}
\usepackage{caption} % for captionof

\setbeamercolor{background canvas}{bg=burlywood!25}
\usepackage[table,xcdraw]{xcolor}

\DeclareMathOperator*{\argmin}{arg\,min}
\definecolor{darkblue}{rgb}{0.1, 0.1, 0.44}
\definecolor{lightgray}{rgb}{0.9, 0.9, 0.9}
\definecolor{burntumber}{rgb}{0.54, 0.2, 0.14}
\definecolor{sienna}{rgb}{0.53, 0.18, 0.09} 
\definecolor{rosewood}{rgb}{0.4, 0.0, 0.04}
\definecolor{burlywood}{rgb}{0.87, 0.72, 0.53}
\definecolor{mahogany}{rgb}{0.75, 0.25, 0.0}

\newcommand{\footleft}{\normalsize{\hspace{0.5em}https://spire.ee.iisc.ac.in/}}
\newcommand{\footright}{\normalsize{amartyaveer72@gmail.com, saurabhk0317@gmail.com, prasantg@iisc.ac.in\hspace{0.5em}}}

\usepackage{pifont}
\newcommand{\starbullet}{\ding{72}}

\usepackage[utf8]{inputenc}         % Ensure UTF-8 encoding
\newcommand{\cmark}{{\color{green!60!black}\ding{51}}}     % Check mark ✔
\newcommand{\warn}{{\color{orange!80!black}\ding{46}}}     % Warning ❗
\newcommand{\xmark}{{\color{red!70!black}\ding{55}}}       % Cross ✘
\newcommand{\info}{{\color{blue!70!black}\ding{72}}}       % Info ℹ


\title{\Huge{\textbf{Improving Dialect Identification in Indian Languages Using Multimodal Features\\ from Dialect Informed ASR}}}
\author{\Large{Amartyaveer*, Saurabh Kumar*, Sumit Sharma*, Sathvik Udupa, Sandhya Badiger, Abhayjeet Singh, Deekshitha G,\\ Jesuraja Bandekar, Savitha Murthy, Prasanta Kumar Ghosh}}
\institute{\Large{Department of Electrical Engineering, Indian Institute of Science, Bengaluru -- 560012, India}}

\begin{document}
\begin{frame}{}

\vspace{-1em}
\begin{columns}[t]

    % ---------- Left Column: Dataset ----------
    \column{0.49\textwidth}
    \begin{block}{\Large\textbf{Dataset}}
    \begin{columns}%[onlytextwidth]

        % ---- 70% width: Map ----
        \begin{column}{0.69\textwidth}
        \vspace{0pt}
        \centering
        \includegraphics[width=\linewidth]{presentation/Images/poster_dialect_map2.png}
        \vspace{0.4em}
        {\small District-wise distribution of 8 Indian languages (left) and 5 Bengali dialects (right) used in this work.}
        \end{column}

        % ---- 30% width: Dataset Info ----
        \begin{column}{0.29\textwidth}
        \vspace{0pt}
        A curated subset of the RESPIN Corpus -- a multi-dialect read-speech dataset developed for ASR and DID.\\
        \textbf{(\href{https://respin.iisc.ac.in/}{\texttt{respin.iisc.ac.in}})}

        \vspace{0.4em}
        \textbf{\textcolor{darkblue}{Languages (8):}} Bengali, Bhojpuri,\\ Chhattisgarhi, Kannada, Magahi,\\ Maithili, Marathi, Telugu

        \vspace{0.4em}
        \textbf{\textcolor{darkblue}{Dialect Coverage:}} 33 dialects\\ across 8 Indian languages

        \vspace{0.4em}
        \textbf{\textcolor{darkblue}{Split per language:}}
        \begin{itemize}\setlength\itemsep{0.3em}
            \item Train: 140–175h ({\small 1000-1700 speakers \& 17k-19k sentences})
            \item Dev: \ensuremath{\sim} 2h ({\small 60-100 speakers \& 500-700 sentences})
            \item Test: 6–8h ({\small 120-200 speakers \& 1300-2000 sentences})
        \end{itemize}

        \vspace{0.4em}
        \textbf{\textcolor{darkblue}{Note:}} No speaker/sentence overlap across dialects.
        \end{column}
    \end{columns}
    \end{block}

    % ---------- Right Column: Proposed Method ----------
    \column{0.49\textwidth}
    \begin{block}{\Large\textbf{Proposed Method}}
    \begin{columns} %[onlytextwidth]

        % ---- 70% width: Diagram ----
        \begin{column}{0.65\textwidth}
        \vspace{0pt}
        \centering
        \includegraphics[width=\linewidth]{presentation/Images/model_poster.png}
        \vspace{0.4em}
        {\small Block diagram of the proposed architecture.}
        \end{column}
        
        % ---- 30% width: Method Info ----
        \begin{column}{0.34\textwidth}
        \vspace{0pt}
        \textbf{\textcolor{darkblue}{Multimodal Architecture:}}
        \begin{itemize}\setlength\itemsep{0.3em}
            \item \textbf{ASR Block:} IndicWav2Vec + Conformer encoder
            \item \textbf{DID Block:} RoBERTa\textsuperscript{4} on ASR hypothesis and CTC logits
        \end{itemize}
        
        \vspace{0.4em}
        \textbf{\textcolor{darkblue}{Objective Function:}}
        \[
        L = \lambda_{\text{CTC}} L_{\text{CTC}} + (1 - \lambda_{\text{CTC}}) L_{\text{ATT}} + \gamma_{\text{CE}} L_{\text{CE}}
        \]
        
        \vspace{0.4em}
        \textbf{\textcolor{darkblue}{Key Insight:}} Jointly models speech and text cues for dialect prediction.
        
        \vspace{0.4em}
        \textbf{\textcolor{darkblue}{Training Details:}}
        \begin{itemize}\setlength\itemsep{0.3em}
            \item Joint training of ASR and DID modules.
            \item \textbf{Conformer:} 8 blocks, 4 heads, 256-dim; \textbf{Transformer decoder:} 6 layers, 8 heads
            \item Loss weights: $\lambda_{\text{CTC}} = 0.5$, $\gamma_{\text{CE}} = 6$
            \item ASR-generated text used as input to \textbf{ROB Block}.
        \end{itemize}
        \end{column}

    \end{columns}
    % \end{minipage}
    \end{block}

\end{columns}

\vspace{-0.5em}

% ------------------ 3-COLUMN CONTENT BLOCK ------------------
\begin{columns}[t,totalwidth=\textwidth]

% ---------- First Column ----------
\begin{column}{0.25\textwidth}

% ---------- INTRODUCTION ----------
\begin{block}{\Large\textbf{Introduction}}

\begin{minipage}{\linewidth}
\textbf{\textcolor{darkblue}{Why Dialect Identification?}}
\begin{itemize}\setlength\itemsep{0.2em}
    \item India has hundreds of dialects, but limited DID research.
    \item DID enhances ASR personalization in multi-dialect regions.
\end{itemize}
\end{minipage}

\vspace{0.6em}

\begin{minipage}{\linewidth}
\textbf{\textcolor{darkblue}{Challenges}}
\begin{itemize}\setlength\itemsep{0.2em}
    \item DID is harder than Language Identification (LID).
    \item Dialects share phonetic, lexical, and syntactic traits\textsuperscript{1}.
    \item Scarcity of annotated dialectal datasets.
\end{itemize}
\end{minipage}

\vspace{0.6em}

\begin{minipage}{\linewidth}
\textbf{\textcolor{darkblue}{Limitations of Prior Work}}
\begin{itemize}\setlength\itemsep{0.2em}
    \item Text-only models lack acoustic/prosodic information.
    \item Audio-only models miss rich linguistic structure\textsuperscript{2}.
    \item ASR-based models underutilize both modalities\textsuperscript{3}.
\end{itemize}
\end{minipage}

\vspace{0.6em}

\begin{minipage}{\linewidth}
\textbf{\textcolor{darkblue}{Our Contributions}}
\begin{itemize}\setlength\itemsep{0.2em}
    \item First large-scale dialect identification (DID) study across 8 Indian languages and 33 dialects.
    \item Multimodal architecture combining speech and ASR-text.
    \item IndicWav2Vec layer analysis for dialect-sensitive features.
\end{itemize}
\end{minipage}

\end{block}

\begin{block}{\footnotesize \textbf{Acknowledgement}}
{\footnotesize
\begin{itemize}\setlength\itemsep{0.2em}
    \item Supported by the RESPIN project (Bill \& Melinda Gates Foundation).
    \item Special thanks to the b, Navana Tech, and IISc Bengaluru.
\end{itemize}
}
\end{block}

\vspace{-0.5em}
% ---------- REFERENCES AND QR CODE ----------
\begin{block}{\footnotesize \textbf{References AND QR Code}}

\begin{columns}
    \vspace{-0.5em}
    % ---- Left: References ----
    \begin{column}{0.75\textwidth}
    \vspace{0pt}  % This forces top alignment
    {\scriptsize
    \begin{itemize}\setlength\itemsep{0.2em}
        \item [1.] Udupa et al., ”Gated Multi Encoders and Multitask Objectives for Dialectal Speech Recognition in Indian Languages,” In Proc. ASRU, 2023.
        \item [2.] Desplanques et al., “ECAPA-TDNN: Emphasized Channel Attention, Propagation
and Aggregation in TDNN-Based Speaker Verification,” Interspeech, 2020.
        \item [3.] Lonergan et al., “Low-resource speech recognition and dialect identification of Irish
in a multi-task framework,” Odyssey, 2024.
        \item [4.] Liu et al., “RoBERTa: A Robustly Optimized BERT Pretraining Approach,” ArXiv, 2019.
    \end{itemize}
    }
    \vspace{0.8em}
    \end{column}

    % ---- Right: QR Code ----
    \begin{column}{0.24\textwidth}
    \vspace{0pt}  % This forces top alignment
    \centering
    \includegraphics[width=0.95\linewidth]{presentation/Images/qrcode.png}
    \vspace{0.3em}
    {\small (Full paper)}
    \end{column}
\end{columns}

\end{block}

\end{column}

% Second Column
\begin{column}{0.28\textwidth}
\begin{block}{\Large\textbf{Results – DID Performance}}

% ---------- Accuracy Table + Observations ----------
        \centering
        \resizebox{\textwidth}{!}{%
        \begin{tabular}{llccccccccc}
            \toprule
            \textbf{Type} & \textbf{Method} & \textbf{bh} & \textbf{bn} & \textbf{ch} & \textbf{kn} & \textbf{mg} & \textbf{mr} & \textbf{mt} & \textbf{te} & \textbf{Avg} \\
            \midrule
        
            \multirow{1}{*}{Text} 
            & ROB & 72.52 & 63.16 & 74.70 & 71.96 & \textbf{87.22} & 76.82 & \textbf{87.77} & 65.00 & 74.89 \\
            
            \midrule
        
            \multirow{4}{*}{Audio} 
            & CON        & 45.20 & 51.17 & 49.31 & 60.10 & 67.21 & 60.74 & 59.92 & 57.46 & 56.39 \\
            & ETD        & 49.96 & 52.55 & 56.78 & 58.52 & 71.04 & 61.87 & 62.96 & 60.11 & 59.22 \\
            & SSL-ETD    & 63.85 & 65.32 & 67.87 & 72.80 & 78.94 & 74.72 & 75.10 & 72.30 & 71.36 \\
            & SSL-CON    & 65.27 & 67.86 & 69.35 & 73.40 & 80.05 & 73.11 & 73.42 & 74.37 & 72.10 \\
        
            \midrule
        
            \multirow{2}{*}{ASR} 
            & SSL-ASR     & 72.30 & 73.08 & 75.91 & 78.46 & 85.53 & 79.52 & 80.21 & 76.24 & 77.66 \\
            & SSL-ASR-ROB & \textbf{75.56} & \textbf{73.65} & \textbf{76.76} & \textbf{81.49} & 86.79 & \textbf{81.73} & 83.81 & \textbf{78.68} & \textbf{79.81} \\
        
            \bottomrule
        \end{tabular}
        }

    \vspace{0.4em}

    \begin{itemize}\setlength\itemsep{0.2em}
        \item ROB excels on Magahi and Maithili.
        \item SSL-audio methods outperform CON and ETD.
        \item SSL-ASR best among existing audio/text (\textbf{77.66\%}).
        \item SSL-ASR-ROB (proposed) highest overall: \textbf{79.81\%}.
    \end{itemize}

\vspace{0.8em}

% ---------- Layer Plot + Findings ----------
    % \centering
    \includegraphics[width=0.95\linewidth]{presentation/Images/layer_plot}
    \vspace{0.3em}
    \begin{itemize}\setlength\itemsep{0.2em}
        \item Mid-to-late layer outputs outperform others.
        \item Layers 7–11 capture best dialectal cues.
        \item Weighted sum of outputs of layers 7–11 achieves \textbf{72.16\%}.
    \end{itemize}
% \end{columns}

\end{block}
\end{column}


% Third Column
\begin{column}{0.45\textwidth}

\begin{block}{\Large\textbf{Results - Confusion Matrix}}
\vspace{-0.8em}
\begin{columns}[t]

% ---------- Left: Image ----------
\begin{column}{0.7\textwidth}
\vspace{0pt}  % This forces top alignment
\centering
\includegraphics[width=\linewidth]{presentation/Images/cm_did}
\end{column}

% ---------- Right: Highlights ----------
\begin{column}{0.29\textwidth}
\vspace{0pt}  % This forces top alignment
\begin{itemize}\setlength\itemsep{0.6em}
    \item \textbf{\textcolor{darkblue}{Overall:}} High accuracy across most dialects.
    \item \textbf{\textcolor{darkblue}{Best:}} \textit{mg D4} (97.7\%), \textit{mr D1} (96.9\%).
    \item \textbf{\textcolor{darkblue}{Lower:}} \textit{mr D2} (53.2\%), \textit{ch D2} (66.6\%) — likely due to overlapping phonetic features and limited distinctiveness.
\end{itemize}
\end{column}
\end{columns}
\end{block}

\begin{block}{\Large\textbf{Results - ASR Performance}}
    % ---------- Left Column: Table (70%) ----------
    \vspace{-0.8em}
    \begin{columns}
    \begin{column}{0.54\textwidth}
    \vspace{0pt}  % This forces top alignment
    \centering
    \renewcommand{\arraystretch}{1.2}
    \begin{table}[h!]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{lccccccccc}
        \toprule
        \textbf{Method} & \textbf{bh} & \textbf{bn} & \textbf{ch} & \textbf{kn} & \textbf{mg} & \textbf{mr} & \textbf{mt} & \textbf{te} & \textbf{Avg} \\
        \midrule
        SSL-ASR     & 4.96 & 4.63 & 3.81 & 4.83 & 6.89 & 3.60 & 5.69 & 4.17 & \textbf{4.82} \\
        SSL-ASR-ROB & 4.88 & 4.90 & 4.06 & 5.04 & 6.98 & 3.55 & 5.80 & 4.38 & \textbf{4.95} \\
        \bottomrule
    \end{tabular}
    }
    \end{table}
    \end{column}

    % ---------- Right Column: Key Observations (30%) ----------
    \begin{column}{0.46\textwidth}
    \vspace{0pt}  % This forces top alignment
    \begin{itemize} \setlength\itemsep{0.4em}
        \item SSL-ASR achieves the best average CER: \textbf{4.82\%}.
        \item SSL-ASR-ROB shows a slight increase: \textbf{4.95\%}.
        \item Minor CER increase due to dialect supervision.
    \end{itemize}
    \end{column}
    \end{columns}
\end{block}

\vspace{-0.4em}
\begin{block}{\Large\textbf{Conclusions and Future Works}}
\begin{columns}[t]
\begin{column}{0.54\textwidth}
\vspace{0pt}  % This forces top alignment
% ------------------ CONCLUSIONS ------------------
\textbf{\textcolor{darkblue}{Key Findings:}}
\begin{itemize}\setlength\itemsep{0.5em}
    \item Multimodal DID architecture combining speech and text cues improves dialect identification in Indian languages.
    \item A slight trade-off is observed between DID accuracy and ASR performance.
\end{itemize}

\vspace{0.8em}


\end{column}

\begin{column}{0.45\textwidth}
\vspace{0pt}  % This forces top alignment
\textbf{\textcolor{darkblue}{Future Work:}}
\begin{itemize}\setlength\itemsep{0.5em}
    \item Address dialectal overlap and mitigate ASR degradation.
    \item Explore end-to-end multimodal modelling alternatives.
\end{itemize}
\end{column}
\end{columns}
\end{block}


\end{column}
\end{columns}

\end{frame}
\end{document}
